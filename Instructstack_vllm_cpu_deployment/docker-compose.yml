version: "3.8"

services:
  vllm:
    image: hamzaak4/vllm-cpu-image:Latest1.1
    container_name: vllm_server
    privileged: true
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
    environment:
      DEFAULT_MODEL: "sshleifer/tiny-gpt2"  # Fixed syntax
    command: >
      bash -c "source /opt/conda/etc/profile.d/conda.sh &&
      conda activate vllm_env &&
      vllm serve /models/$$DEFAULT_MODEL --device cpu --host 0.0.0.0 --port 8000"
    networks:
      - vllm-net

  fastapi_app:
    image: fastapi_vllm_cpu:Latest
    container_name: fastapi-app
    ports:
      - "9000:9000"
    volumes:
      - ./models:/models
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - VLLM_API_URL=http://vllm:8000/v1/completions
      - HOST_MODEL_PATH=/home/hamza/Instructstack/models  
    depends_on:
      - vllm
    networks:
      - vllm-net

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - vllm-net
    

  node_exporter:
    image: prom/node-exporter
    container_name: node_exporter
    ports:
      - "9100:9100"
    networks:
      - vllm-net

  
    
  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    networks:
      - vllm-net
    volumes:
      - grafana-storage:/var/lib/grafana

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8081:8080"
    privileged: true
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/lib/docker/image:/var/lib/docker/image:ro
      - /var/lib/docker/overlay2:/var/lib/docker/overlay2:ro
    networks:
      - vllm-net



networks:
  vllm-net:
    driver: bridge

volumes:
  grafana-storage:    